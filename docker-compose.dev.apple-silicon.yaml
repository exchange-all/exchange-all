version: "3.9"

name: exchange_microservice

volumes:
  redpanda:
    driver: local

services:

  redpanda:
    container_name: redpanda
    image: redpandadata/redpanda:v23.2.17
    command:
      - redpanda start
      - --smp 1
      - --overprovisioned
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      # Address the broker advertises to clients that connect to the Kafka API.
      # Use the internal addresses to connect to the Redpanda brokers
      # from inside the same Docker network.
      # Use the external addresses to connect to the Redpanda brokers
      # from outside the Docker network.
      - --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      # Address the broker advertises to clients that connect to the HTTP Proxy.
      - --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      # Redpanda brokers use the RPC API to communicate with each other internally.
      - --rpc-addr redpanda:33145
      - --advertise-rpc-addr redpanda:33145
      - --mode dev-container
    ports:
      - "18081:18081"
      - "18082:18082"
      - "19092:19092"
      - "19644:9644"
    volumes:
      - redpanda:/var/lib/redpanda/data
    restart: on-failure
    healthcheck:
      test: [ "CMD-SHELL", "rpk cluster health | grep -E 'Healthy:.+true' || exit 1" ]
      interval: 15s
      timeout: 3s
      retries: 5
      start_period: 5s

  console:
    container_name: redpanda-console
    image: redpandadata/console:v2.3.7
    entrypoint: /bin/sh
    command: -c "echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/console"
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["redpanda:9092"]
          schemaRegistry:
            enabled: true
            urls: ["http://redpanda:8081"]
        redpanda:
          adminApi:
            enabled: true
            urls: ["http://redpanda:9644"]
        connect:
          enabled: true
          clusters:
            - name: local-connect-cluster
              url: http://connect:8083
    depends_on:
      - redpanda
    ports:
      - "8080:8080"
    restart: on-failure

  exchange-db:
    container_name: exchange-db
    image: mongo:latest
    platform: linux/arm64
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root
      MONGO_INITDB_DATABASE: exchange
    ports:
      - "27017:27017"
    restart: on-failure
    healthcheck:
      test: [ "CMD", "mongo", "--eval", "db.adminCommand('ping')" ]
      interval: 5s
      timeout: 5s

  orderbook-db:
    container_name: orderbook-db
    image: mongo:latest
    platform: linux/arm64
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root
      MONGO_INITDB_DATABASE: orderbook
    ports:
      - "27018:27017"
    restart: on-failure
    healthcheck:
      test: [ "CMD", "mongo", "--eval", "db.adminCommand('ping')" ]
      interval: 5s
      timeout: 5s

  redis-db:
    container_name: redis-db
    image: redis/redis-stack:latest
    ports:
      - "6379:6379"
      - "8001:8001"
    restart: on-failure
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 5s

  consul-server:
    image: hashicorp/consul:latest
    container_name: consul-server
    restart: always
    volumes:
      - ./infrastructure/consul/server.json:/consul/config/server.json:ro
    ports:
      - "8500:8500"
      - "8600:8600/tcp"
      - "8600:8600/udp"
    command: "agent"

  otel-collector:
    image: otel/opentelemetry-collector:latest
    command: [ "--config=/etc/otel-collector.yaml" ]
    volumes:
      - ./infrastructure/observability/otel-collector.yaml:/etc/otel-collector.yaml
    ports:
      - "4317:4317"  # otlp grpc
    depends_on:
      - tempo

  # To eventually offload to Tempo...
  tempo:
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./infrastructure/observability/tempo.yaml:/etc/tempo.yaml
      - ./infrastructure/observability/tempo-data:/tmp/tempo
    ports:
      - "3200"   # tempo
      - "4317"  # otlp grpc
      - "4318"  # otlp http

  prometheus:
    image: prom/prometheus:latest
    command:
      - --config.file=/etc/prometheus.yaml
      - --web.enable-remote-write-receiver
      - --enable-feature=exemplar-storage
    volumes:
      - ./infrastructure/observability/prometheus.yaml:/etc/prometheus.yaml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:10.1.1
    volumes:
      - ./infrastructure/observability/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    ports:
      - "3000:3000"

  questdb:
    container_name: questdb
    image: questdb/questdb:latest
    ports:
      - "9000:9000"
      - "9009:9009"
      - "8812:8812"
      - "9003:9003"
    restart: on-failure
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/health" ]
      interval: 5s
      timeout: 5s
